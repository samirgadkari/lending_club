---
title: "Lending club"
author: "Samir Gadkari"
date: "3/24/2021"
output: html_document
---

```{r include=FALSE}
library(tidyverse)
library(readr)
```

## 1.1 Read in data
Since the accepted/rejected files are large, grep it and save all
"credit_card" rejections to another file. This will make it faster
(and possible) to load it in memory during the read_csv call.

```{bash}
FILE=$DATASETS/financial_datasets/all_lending_club_loan_data/accepted_credit_card_2007_to_2018Q4_2.csv

if [ ! -f "$FILE" ]; then
  grep "credit_card" $DATASETS/financial_datasets/all_lending_club_loan_data/accepted_2007_to_2018Q4_2.csv >> $DATASETS/financial_datasets/all_lending_club_loan_data/accepted_credit_card_2007_to_2018Q4_2.csv
fi

FILE=$DATASETS/financial_datasets/all_lending_club_loan_data/rejected_credit_card_2007_to_2018Q4_2.csv

if [ ! -f "$FILE" ]; then
  grep "credit_card" $DATASETS/financial_datasets/all_lending_club_loan_data/rejected_2007_to_2018Q4_2.csv >> $DATASETS/financial_datasets/all_lending_club_loan_data/rejected_credit_card_2007_to_2018Q4_2.csv
fi
```

```{r}
data_path <- paste0(Sys.getenv("DATASETS"), "/financial_datasets",
                   "/all_lending_club_loan_data")

accepted_cc <- read_csv(
  paste0(data_path, "/accepted_credit_card_2007_to_2018Q4_2.csv"),
  col_types = cols(desc = col_character(),
                   revol_bal_joint = col_double(),
                   sec_app_fico_range_low = col_double(), 
                   sec_app_fico_range_high = col_double(),
                   sec_app_earliest_cr_line =
                     col_double(),    
                   sec_app_inq_last_6mths = col_double(),
                   sec_app_mort_acc = col_double(),
                   sec_app_open_acc = col_double(),
                   sec_app_revol_util = col_double(),
                   sec_app_open_act_il = col_double(),    
                   sec_app_num_rev_accts = col_double(),
                   sec_app_earliest_cr_line = 
                     col_skip(),
                   sec_app_chargeoff_within_12_mths =
                     col_double(),
                   sec_app_collections_12_mths_ex_med =
                     col_double(),
                   sec_app_mths_since_last_major_derog =
                     col_double()
                  ),
  progress = show_progress())

head(accepted_cc)
nrow(accepted_cc)
```
```{r}
nrow(accepted_cc[accepted_cc$purpose == "credit_card", ])
```

Great !! Now we have half a million row values to work with (and that's
just for the accepted credit applications).

Let's see which columns are full of NAs or Nulls.
```{r}
(selected_cols <- accepted_cc %>%
  select(which(colMeans(is.na(.)) < 0.02)) %>%
  names())
```
Now we have the columns where the number of NAs are less than 2%.
We should do this, since this is lending club data, and columns which are
expected to be useful will not have significant NAs.

Let's select these columns, and remove any rows that have NA values in it.
This way, we won't have to deal with any missing values. If our model is
bad, we can always interpolate the missing values.

```{r}
accepted_cc <- na.omit(accepted_cc[ , selected_cols])
head(accepted_cc)
```

Now we have a large number of rows, enough to work with.

```{r}
print(paste(names(accepted_cc), collapse = ",  "))
```
```{r}
unique_values <- function(ref) {
  paste(unique(ref), collapse = ",   ")
}

unique_char_col_vals <- function(df_name, df) {
  writeLines(
    stringr::str_glue("{df_name}: ------------------------------->>>>>"))
  
  result <- as.list(df %>%
        select(df %>%
                 select_if(is.character) %>%
                 select(!contains("date", ignore.case = TRUE)) %>%
                 summarise(across(everything(), n_distinct)) %>%
                 select(where(~.x[[1]] < 40)) %>%
                 names()) %>%
        summarise(across(everything(), unique_values)))

  print(result)
  
  writeLines(
    stringr::str_glue("<<<<<--------------------------- :{df_name}"))
}

unique_char_col_vals("accepted_cc", accepted_cc)
```


```{r}
n_occur <- data.frame(table(as.integer(accepted_cc$id)))
n_occur[n_occur$Freq > 1, ]
```


Each id value is unique, and none of them are member IDs. This means each line is for a separate credit card.

```{r}
print(paste(names(accepted_cc), collapse = ",  "))
```
```{r}
accepted_cc <- accepted_cc %>%
  mutate(issue_date = 
           as.POSIXct(
             strptime(paste0("01-", accepted_cc$issue_d),  # strptime requires
                      "%d-%b-%Y")),                        # a full date
         .after = issue_d
         ) %>%  
  select(-issue_d)

min(accepted_cc[["issue_date"]])
max(accepted_cc[["issue_date"]])
```

There are accounts from June 2012 through December 2018.

Let's look at the distribution of the dates:

```{r}
accepted_cc %>%
  ggplot(aes(x = issue_date)) +
  geom_histogram(bins = 30)
```
```{r}
head(accepted_cc$pub_rec)              # public records count?
head(accepted_cc$pub_rec_bankruptcies) # public record bankruptcies count
head(accepted_cc$funded_amnt)
head(accepted_cc$funded_amnt_inv)

accepted_cc[accepted_cc$funded_amnt != accepted_cc$funded_amnt_inv, ]
```

